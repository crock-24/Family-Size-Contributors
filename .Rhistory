teenconcerns[teenconcerns$Concern == 5,]
teenconcerns[teenconcerns$Concern == 2, ]
teenconcerns[teenconcerns$Concern == 4, ]
teenconcerns$Counts
teenconcerns$Concern
teenconcerns$Sex
teenconcerns[teenconcerns$Concern != 3, ]
teenconcerns[teenconcerns$Concern != 'menstrual', ]
teenconcerns[teenconcerns$Concern != 'Menstrual', ]
data(cervical)
cervical
data(danishlc)
head(danishlc)
library(GLMsData)
data(danishlc)
head(danishlc)
danishlc$Rate <- danishlc$Cases / danishlc$Pop * 1000 # Rate per 1000
danishlc$Age <- ordered(danishlc$Age, # ensure age-order is preserved
levels = c("40-54", "55-59", "60-64", "65-69", "70-74", ">74") )
# Figure 5.1
danishlc$City  <- abbreviate(danishlc$City, 1) # abbreviate city names
matplot(xtabs(Rate ~ Age + City, data = danishlc),
pch = 1:4, lty = 1:4, type = "l", lwd = 2, col = 3:6,
axes = FALSE, ylim = c(0, 25), xlab = "Age group", ylab = "Cases/1000")
matpoints(xtabs(Rate ~ Age + City, data = danishlc), pch = 1:4, col = 3:6)
axis(side = 1, at = 1:6, labels = levels(danishlc$Age))
axis(side = 2, las = 1)
box()
legend("topleft", col = 3:6, pch = 1:4, lwd = 2, lty = 1:4,
merge = FALSE, legend = c("Fredericia", "Horsens", "Kolding", "Vejle"))
# compare two dummy coding for ordered variables
data(cervical)
str(cervica)
str(cervical)
cervical$Deaths/cervical$Wyears
library(GLMsData)
data(cervical)
cervical$Country
?cervical
?table
data(dwomen)
str(dwomen)
data(grazing)
str(grazing)
grazing$Birds
grazing[(grazing$When == 1) & (grazing$Grazed == 1), ]
grazing[(grazing$When == 'After') & (grazing$Grazed == 'Feral'), ]
grazing[(grazing$When == 'After') & (grazing$Grazed == 'Feral'),]
grazing[(grazing$When == 'After') & (grazing$Grazed == 'Feral'),]$Birds
data(ccancer)
str(ccancer)
ccancer[ccancer$Count = 0,]
ccancer[ccancer$Count == 0,]
ccancer[(ccancer$Site != "Breast") & (ccancer$Gender != "M"), ]
ccancer[(ccancer$Site == "Breast") & (ccancer$Gender == "M"), ]
ccancer[~ (ccancer$Site == "Breast") & (ccancer$Gender == "M"), ]
ccancer[~(ccancer$Site == "Breast") & ~(ccancer$Gender == "M"), ]
ccancer[~((ccancer$Site == "Breast") & (ccancer$Gender == "M")), ]
ccancer[!((ccancer$Site == "Breast") & (ccancer$Gender == "M")), ]
str(ccancer)
ccancer$Region
ccancer$Site
ccancer
ccancer
getwd()
pchisq(5.05, df = 1, lower.tail = F)
pchisq(0.9, df = 1, lower.tail = F)
pchisq(2.21, df = 1, lower.tail = F)
pchisq(19.97, df = 1, lower.tail = F)
pchisq(2.86, df = 1, lower.tail = F)
pchisq(7.04, df = 1, lower.tail = F)
pchisq(10.95), df = 1, lower.tail = F)
pchisq(10.95, df = 1, lower.tail = F)
0.1220/0.0543
0.6604/0.1287
0.207/0.2186
0.4896/0.3294
-0.929/0.208
-0.087/0.0515
-0.224/0.0845
-0.273/0.0825
pnorm(2.247, lower.tail = F)
pnorm(5.13, lower.tail = F)
pnorm(0.95, lower.tail = F)
pnorm(1.486, lower.tail = F)
pnorm(-4.466, lower.tail = T)
pnorm(-1.689, lower.tail = T)
pnorm(-2.651, lower.tail = T)
pnorm(-0.273, lower.tail = T)
pnorm(-3.31, lower.tail = T)
pt(-1.93, df = 1)
pt(-1.93, df = 1141)
qt(0.975, df = 1141)
0.1415*qt(0.975, df = 1141)
-0.2729 + 0.2776294
-0.2729 - 0.2776294
li e
lime
library(GLMsData)
data(lime)
str(lime)
((lime.glm$deviance - lime.glm2$deviance)/(lime.glm$df.residual - lime.glm2$df.residual)) / (lime.glm$deviance/lime.glm2$df.residual)
lime.glm <- glm(Foliage ~ log(DBH), family = Gamma(link = 'log'), data = lime)
lime.glm2 <- glm(Foliage ~ log(DBH) + Age, family = Gamma(link = 'log'), data = lime)
anova(lime.glm, lime.glm2)
((lime.glm$deviance - lime.glm2$deviance)/(lime.glm$df.residual - lime.glm2$df.residual)) / (lime.glm$deviance/lime.glm2$df.residual)
(lime.glm$df.residual - lime.glm2$df.residual)
(lime.glm$deviance - lime.glm2$deviance)
(lime.glm$deviance/lime.glm2$df.residual)
(lime.glm$deviance
)
lime.glm2$df.residual
library(GLMsData)
data("emeraldaug")
emeraldaug
str(emeraldaug)
?tweedie.profile()
(6) (5 points) For the fitted model using SOI phases, find the parameters of the underlying Poisson and gamma distributions (lambda, Pi0, Mu, and Phi* ) for Phase 2 using the estimated dispersion parameter from the GLM model.
install.packages('tweedie')
rain.glm <- glm(Rain ~ SOI, data = emeraldaug, family = tweedie(link.power = 0, var.power = 1.55))
library(tweedie)
data("emeraldaug")
tweedie.profile(Rain ~ SOI, data = emeraldaug, xi.vec = seq(1.02, 2.0, by = 0.02))
rain.tweed
rain.tweed <- tweedie.profile(Rain ~ SOI, data = emeraldaug, xi.vec = seq(1.02, 2.0, by = 0.02))
# load data
data(quilpie)
head(quilpie)
# Example 6.7: estimate index parameter - group by SOI Phase
mn <- with(quilpie, tapply(Rain, Phase, "mean"))
vr <- with(quilpie, tapply(Rain, Phase, "var"))
summary(lm(log(vr) ~ log(mn)))
# Example 6.7: estimate index parameter - group by Decade
Decade <- cut(quilpie$Year, breaks = seq(1920, 1990, by = 10))
mn <- tapply( quilpie$Rain, Decade, "mean")
vr <- tapply( quilpie$Rain, Decade, "var")
summary(lm(log(vr) ~ log(mn)))
# Example 6.8: estimate index parameter - profile likelihood
# Figure 6.10
par(mfrow = c(2, 2))
quilpie$Phase <- factor(quilpie$Phase) # declare Phase as a factor
plot(Rain ~ Phase, data = quilpie, ylab = "Total July rainfall", ylim = c(0, 100), las = 1)
out <- tweedie.profile(Rain ~ Phase, do.plot = TRUE, data = quilpie)
out$xi.max # estimated index parameter
out$ci # ci of index parameter
out$phi.max # dispersion parameter
tweedie.profile(Rain ~ SOI, data = emeraldaug, xi.vec = seq(1.02, 2.0, by = 0.02))
data("quilpie")
quilpie
emeraldaug
# load data
data(quilpie)
head(quilpie)
# Example 6.7: estimate index parameter - group by SOI Phase
mn <- with(quilpie, tapply(Rain, Phase, "mean"))
vr <- with(quilpie, tapply(Rain, Phase, "var"))
summary(lm(log(vr) ~ log(mn)))
# Example 6.7: estimate index parameter - group by Decade
Decade <- cut(quilpie$Year, breaks = seq(1920, 1990, by = 10))
mn <- tapply( quilpie$Rain, Decade, "mean")
vr <- tapply( quilpie$Rain, Decade, "var")
summary(lm(log(vr) ~ log(mn)))
# Example 6.8: estimate index parameter - profile likelihood
# Figure 6.10
par(mfrow = c(2, 2))
quilpie$Phase <- factor(quilpie$Phase) # declare Phase as a factor
plot(Rain ~ Phase, data = quilpie, ylab = "Total July rainfall", ylim = c(0, 100), las = 1)
out <- tweedie.profile(Rain ~ Phase, do.plot = TRUE, data = quilpie)
out$xi.max # estimated index parameter
out$ci # ci of index parameter
out$phi.max # dispersion parameter
# load data
data(quilpie)
head(quilpie)
# Example 6.7: estimate index parameter - group by SOI Phase
mn <- with(quilpie, tapply(Rain, Phase, "mean"))
vr <- with(quilpie, tapply(Rain, Phase, "var"))
summary(lm(log(vr) ~ log(mn)))
# Example 6.7: estimate index parameter - group by Decade
Decade <- cut(quilpie$Year, breaks = seq(1920, 1990, by = 10))
mn <- tapply( quilpie$Rain, Decade, "mean")
vr <- tapply( quilpie$Rain, Decade, "var")
summary(lm(log(vr) ~ log(mn)))
# Example 6.8: estimate index parameter - profile likelihood
# Figure 6.10
par(mfrow = c(2, 2))
quilpie$Phase <- factor(quilpie$Phase) # declare Phase as a factor
plot(Rain ~ Phase, data = quilpie, ylab = "Total July rainfall", ylim = c(0, 100), las = 1)
out <- tweedie.profile(Rain ~ Phase, do.plot = TRUE, data = quilpie)
out$xi.max # estimated index parameter
out$ci # ci of index parameter
out$phi.max # dispersion parameter
# Figure 6.13
par(mfrow = c(2, 2))
bd.means <- with(breakdown, tapply(Strength, list(Time, Temperature), "mean"))
# load data
data(breakdown)
head(breakdown)
breakdown$Time <- factor(breakdown$Time)
breakdown$Temperature <- factor(breakdown$Temperature)
summary(breakdown)
# Figure 6.13
par(mfrow = c(2, 2))
bd.means <- with(breakdown, tapply(Strength, list(Time, Temperature), "mean"))
matplot(bd.means, type= "l", col = 1:4, pch = 1:4, lty = 1:4, las = 1,
ylim = c(0, 20), xlab = "Time", ylab = "Mean strength (kV)", axes = FALSE)
matpoints(bd.means, pch = 1:4, col = 1:4)
axis(side = 1, at = 1:8, labels = levels(breakdown$Time))
axis(side = 2, las = 2)
box()
legend("bottomleft", pch = 1:4, lty = 1:4, col = 1:4, merge = FALSE,
legend = levels(breakdown$Temperature), title = "Temperature" )
# estimate index parameter - Figure 6.14
par(mfrow = c(2, 2))
bd.xi <- tweedie.profile(Strength ~ Time * Temperature, data = breakdown, do.plot = TRUE,
xi.vec = seq(1.02, 2.0, by = 0.02))
# fit tweedie glm
bd.m <- glm( Strength ~ factor(Time) * factor(Temperature),
data = breakdown, family = tweedie(link.power = 0, var.power = bd.xi$xi.max))
emeraldaug
newWBC1 <- sort(log10(leukwbc[leukwbc$AG == 1, ]$WBC))
leukwbc.glm <- glm(Time ~ log10(WBC) + AG:log10(WBC), family = Gamma(link = 'log'), data = leukwbc)
data(leukwbc)
library(GLMsData)
data("leukwbc")
leukwbc.glm <- glm(Time ~ log10(WBC) + AG:log10(WBC), family = Gamma(link = 'log'), data = leukwbc)
leukwbc.glm2 <- glm(Time ~ log10(WBC), family = Gamma(link='log'), data = leukwbc)
qresid(leukwbc.glm2)
plot(cooks.distance(leukwbc.glm2), main = 'cooks distance')
newWBC1 <- sort(log10(leukwbc[leukwbc$AG == 1, ]$WBC))
newWBC2 <- data.frame(WBC = newWBC1)
time.prediction1 <- predict(leukwbc.glm2, newdata = newWBC2, type = "response")
newWBC3 <- sort(log10(leukwbc[leukwbc$AG == 2, ]$WBC))
newWBC4 <- data.frame(WBC = newWBC3)
time.prediction2 <- predict(leukwbc.glm2, newdata = newWBC4, type = "response")
plot(Time ~ log10(WBC), col = AG+1, data = leukwbc, xlab = "Cell count (WBC)", ylab = "Time", pch = '*')
lines(as.vector(time.prediction1) ~ newWBC1, type = 'l', col = 'red')
time.prediction1
predict(leukwbc.glm2, newdata = newWBC2, type = "response")
newWBC2
time.prediction1
newWBC2
newWBC1 <- sort(leukwbc[leukwbc$AG == 1, ]$WBC)
newWBC2 <- data.frame(WBC = newWBC1)
time.prediction1 <- predict(leukwbc.glm2, newdata = newWBC2, type = "response")
time.prediction1
lines(as.vector(time.prediction1) ~ newWBC1, type = 'l', col = 'red')
lines(as.vector(time.prediction1) ~ log10(newWBC1), type = 'l', col = 'red')
newWBC3 <- sort(leukwbc[leukwbc$AG == 2, ]$WBC)
newWBC4 <- data.frame(WBC = newWBC3)
time.prediction2 <- predict(leukwbc.glm2, newdata = newWBC4, type = "response")
lines(as.vector(time.prediction2) ~ log10(newWBC3), type = 'l', col = 'green')
leukwbc$AG
sort(leukwbc[leukwbc$AG == 2, ]$WBC)
time.prediction1
time.prediction2
rrates
data(rrates)
rrates
?glm
str(rrates)
rrates.glm1 <- glm(log(Rate) ~ 1 + Conc.O, family = inverse.gaussian(link = 'log'), data = rrates)
rrates.glm2 <- glm(I(1/Rate) ~ 1 + I(1/Conc.O), family = inverse.gaussian(link = 'log'), data = rrates)
o2.con1 <- sort(rrates$Conc.O)
o2.con2 <- data.frame(Conc.O = o2.con1)
Rate.prediction1 <- predict(rrates.glm1, newdata = o2.con2, type = "response")
Rate.prediction2 <- predict(rrates.glm2, newdata = o2.con2, type = "response")
plot(Rate ~ Conc.O, col = levels(rrates$Temp), data = rrates, xlab = "Oxygen Concentration", ylab = "Rate", pch = '*')
rrates
plot(Rate ~ Conc.O, col = levels(rrates$Temp), data = rrates, xlab = "Oxygen Concentration", ylab = "Rate", pch = '*')
legend('topright', legend = levels(rrates$Temp), pch = '*' , col = levels(rrates$Temp))
Rate.prediction1
rrates
Rate.prediction2 <- predict(rrates.glm2, newdata = o2.con2, type = "response")
Rate.prediction2
data(gsleep)
data(gpsleep)
str(gpsleep)
View(o2.con2)
# Find residuals
lp <- predict(demographics.glm, type = "link") # linear predictor
# Cody Rorick
library(dplyr)
library(statmod)
setwd('/Users/crorick/Documents/MS\ Applied\ Stats\ Fall\ 2023/MA5771/Final\ Project')
demographics <- read.csv('onlinefoods.csv')
demographics = select(demographics, Occupation, Monthly.Income, Educational.Qualifications, Family.size)
demographics$Occupation <- factor(demographics$Occupation)
demographics$Monthly.Income <- factor(demographics$Monthly.Income)
demographics$Educational.Qualifications <- factor(demographics$Educational.Qualifications)
# Making the family size a binomial variable
demographics$Family.size.binom <- factor(cut(demographics$Family.size, breaks = c(0, 2, 6), labels = c("smallFamily", "largeFamily")))
# checking the number of samples in each family size
plot(demographics$Family.size.binom, xlab = 'Family Size', ylab = 'Number Of Samples', main = 'Count Of Samples In Family Sizes')
# Response vs. explanatory variables boxplot
boxplot(Family.size ~ Educational.Qualifications, xlab = 'Educational Qualifications', ylab = 'Family Size', main = 'Educational Qualifications vs Family Size', data = demographics)
boxplot(Family.size ~ Monthly.Income, xlab = 'Monthly Income Range', ylab = 'Family Size', main = 'Income Range vs Family Size', data = demographics)
boxplot(Family.size ~ Occupation, xlab = 'Occupation Type', ylab = 'Family Size', main = 'Occupation Type vs Family Size',data = demographics)
# Response vs explanatory variables prop tables
xtabs( ~ Family.size.binom + Educational.Qualifications, data = demographics)
xtabs( ~ Family.size.binom + Monthly.Income, data = demographics)
xtabs( ~ Family.size.binom + Occupation, data = demographics)
# Fitting the model
demographics.glm <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation, family = binomial(link = 'logit'), data = demographics)
demographics.glm.final <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation - Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
## QQplot shows slightly heavy tails, but not noteworthy enough to question normality.
qqnorm(qresid(demographics.glm))
qqline(qresid(demographics.glm))
# Type 1 AOV
anova(demographics.glm.final)
# Checking if the dispersion parameter is approximately 1, close enough to theoretical dispersion
pearson.stat <- sum(resid(demographics.glm, type = "pearson")^2)
cat(dispersion <- pearson.stat/demographics.glm$df.residual)
# Goodness of fit test cannot be used because binary data does not meet the
# minimum response requirement. m=1 for all responses.
#plotting the quantile residuals vs the constant information fitted values
scatter.smooth(qresid(demographics.glm) ~ asin(sqrt(demographics.glm$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
#checking for influential points
plot(demographics.glm, which = 4)
# Find residuals
lp <- predict(demographics.glm, type = "link") # linear predictor
rW <- resid(demographics.glm, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "C: Working Responses vs Linear Predictors")
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
rW
lp
lp <- predict(demographics.glm.final, type = "link") # linear predictor
rW <- resid(demographics.glm.final, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
demographics.glm.final <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation - Educational.Qualifications:Occupation, family = binomial(link = 'log'), data = demographics)
demographics.glm.final <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation - Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
# Cody Rorick
library(dplyr)
library(statmod)
setwd('/Users/crorick/Documents/MS\ Applied\ Stats\ Fall\ 2023/MA5771/Final\ Project')
demographics <- read.csv('onlinefoods.csv')
demographics = select(demographics, Occupation, Monthly.Income, Educational.Qualifications, Family.size)
demographics$Occupation <- factor(demographics$Occupation)
demographics$Monthly.Income <- factor(demographics$Monthly.Income)
demographics$Educational.Qualifications <- factor(demographics$Educational.Qualifications)
# Making the family size a binomial variable
demographics$Family.size.binom <- factor(cut(demographics$Family.size, breaks = c(0, 2, 6), labels = c("smallFamily", "largeFamily")))
# checking the number of samples in each family size
plot(demographics$Family.size.binom, xlab = 'Family Size', ylab = 'Number Of Samples', main = 'Count Of Samples In Family Sizes')
# Response vs. explanatory variables boxplot
boxplot(Family.size ~ Educational.Qualifications, xlab = 'Educational Qualifications', ylab = 'Family Size', main = 'Educational Qualifications vs Family Size', data = demographics)
boxplot(Family.size ~ Monthly.Income, xlab = 'Monthly Income Range', ylab = 'Family Size', main = 'Income Range vs Family Size', data = demographics)
boxplot(Family.size ~ Occupation, xlab = 'Occupation Type', ylab = 'Family Size', main = 'Occupation Type vs Family Size',data = demographics)
# Response vs explanatory variables prop tables
xtabs( ~ Family.size.binom + Educational.Qualifications, data = demographics)
xtabs( ~ Family.size.binom + Monthly.Income, data = demographics)
xtabs( ~ Family.size.binom + Occupation, data = demographics)
# Fitting the model
demographics.glm <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation, family = binomial(link = 'logit'), data = demographics)
demographics.glm.final <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation - Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
## QQplot shows slightly heavy tails, but not noteworthy enough to question normality.
qqnorm(qresid(demographics.glm))
qqline(qresid(demographics.glm))
# Type 1 AOV
anova(demographics.glm.final)
# Checking if the dispersion parameter is approximately 1, close enough to theoretical dispersion
pearson.stat <- sum(resid(demographics.glm, type = "pearson")^2)
cat(dispersion <- pearson.stat/demographics.glm$df.residual)
# Goodness of fit test cannot be used because binary data does not meet the
# minimum response requirement. m=1 for all responses.
#plotting the quantile residuals vs the constant information fitted values
scatter.smooth(qresid(demographics.glm) ~ asin(sqrt(demographics.glm$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
#checking for influential points
plot(demographics.glm, which = 4)
# Find residuals
lp <- predict(demographics.glm.final, type = "link") # linear predictor
rW <- resid(demographics.glm.final, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
summary(demographics.glm.final)
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Occupation + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
demographics.glm.1 <- glm(Family.size.binom ~ Educational.Qualifications * Monthly.Income * Occupation - Educational.Qualifications:Monthly.Income:Occupation - Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
AIC(demographics.glm.2)
AIC(demographics.glm.1)
logLik(demographics.glm.1)
logLik(demographics.glm.2)
loglik(demographics.glm)
logLik(demographics.glm)
AIC(demographics.glm)
AIC(demographics.glm.1)
AIC(demographics.glm.2)
scatter.smooth(qresid(demographics.glm2) ~ asin(sqrt(demographics.glm2$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
scatter.smooth(qresid(demographics.glm.2) ~ asin(sqrt(demographics.glm.2$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
anova(demographics.glm.2)
pchisq(21.2, 6)
pchisq(3.8, 3)
summary(demographics.glm.2)
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Occupation, family = binomial(link = 'logit'), data = demographics)
anova(demographics.glm.2)
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Occupation + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
anova(demographics.glm.2)
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
plot(demographics.glm.2, which = 4)
scatter.smooth(qresid(demographics.glm.2) ~ asin(sqrt(demographics.glm.2$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
AIC(demographics.glm)
AIC(demographics.glm.1)
AIC(demographics.glm.2)
AIC(demographics.glm)
AIC(demographics.glm.1)
AIC(demographics.glm.2)
pearson.stat <- sum(resid(demographics.glm.2, type = "pearson")^2)
cat(dispersion <- pearson.stat/demographics.glm$df.residual)
scatter.smooth(qresid(demographics.glm.2) ~ asin(sqrt(demographics.glm.2$fitted.values)), xlab = 'Constant information (asin(mean^1/2))', ylab = 'Quantile Residuals', main = 'Quantile Residuals vs Fitted Values')
qqnorm(qresid(demographics.glm.2))
qqline(qresid(demographics.glm.2))
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
# Type 1 AOV
anova(demographics.glm.2)
pchisq(10.84, 4)
pchisq(10.84, 4, lower.tail = F)
pchisq(3.84, 4, lower.tail = F)
pchisq(3.84, 3, lower.tail = F)
pchisq(21.24, 6, lower.tail = F)
summary(demographics.glm.2)
coef(demographics.glm.2)
coefficients(demographics.glm.2)
summary(demographics.glm.2)
demographics$Family.size.binom
demographics.glm.2
levels(demographics$Family.size.binom)[1]
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Educational.Qualifications^2 + Occupation + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
# Find residuals
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Educational.Qualifications^2 + Occupation + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
# Find residuals
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Occupation + Occupation^2 + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
# Find residuals
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
demographics.glm.2 <- glm(Family.size.binom ~ Educational.Qualifications + Occupation + Educational.Qualifications:Occupation, family = binomial(link = 'logit'), data = demographics)
# Find residuals
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
# Find residuals
lp <- predict(demographics.glm.2, type = "link") # linear predictor
rW <- resid(demographics.glm.2, type = "working") # working residuals
z <- rW + lp # working response
# plot of working response against linear predictor
scatter.smooth(z ~ lp, las = 1, ylab = "Working Responses", xlab = "Linear Predictors", main = "Working Responses vs Linear Predictors")
plot(demographics.glm.2, which = 4)
str(demographics)
levels(demographics$Educational.Qualifications)
counts <- c(65, 34, 54, 47, 100, 100, 130, 1441, 76, 116, 111, 191, 67, 130, 48, 105, 62, 104)
typeHousing <- c('tower', 'tower', 'tower', 'tower', 'tower', 'tower', 'apartment', 'apartment', 'apartment', 'apartment', 'apartment', 'apartment', 'house', 'house', 'house', 'house', 'house', 'house')
typeHousing <- c('tower', 'tower', 'tower', 'tower', 'tower', 'tower', 'apartment', 'apartment', 'apartment', 'apartment', 'apartment', 'apartment', 'house', 'house', 'house', 'house', 'house', 'house')
contact <- c('low', 'high', 'low', 'high', 'low', 'high', 'low', 'high', 'low', 'high', 'low', 'high', 'low', 'high', 'low', 'high', 'low', 'high')
data1 <- data.frame(typeHousing, satisfaction, contact, counts)
satisfaction <- c('low', 'low', 'medium', 'medium', 'high', 'high', 'low', 'low', 'medium', 'medium', 'high', 'high', 'low', 'low', 'medium', 'medium', 'high', 'high')
data1 <- data.frame(typeHousing, satisfaction, contact, counts)
housing.glm1 <- multinom(satisfaction ~ typeHousing + contact, weights = counts, data = data1)
library(nnet)
housing.glm1 <- multinom(satisfaction ~ typeHousing + contact, weights = counts, data = data1)
housing.glm2 <- multinom(satisfaction ~ typeHousing + contact + typeHousing:contact, weights =  counts, data = data1)
cat('Deviance of main effects model:')
cat(deviance(housing.glm1))
housing.glm1$residualdf
housing.glm1$residual.df
housing.glm1$resid.df
housing.glm1$residuals
summary(housing.glm1)$resid.df
df.reis
df.residual(housing.glm1)
df.residual(housing.glm2)
?df.residual
summary(housing.glm1)
data1
pchisq(3.9387, 4, lower.tail = F)
pnorm(z.stat)
housing.glm3 <- polr(satisfaction ~ typeHousing + contact, weights =  counts, data = data1)
library(MASS)
housing.glm3 <- polr(satisfaction ~ typeHousing + contact, weights =  counts, data = data1)
satisfaction <- factor(satisfaction)
contact <- factor(contact)
data1$satisfaction <- relevel(data1$satisfaction, ref = 'low')
data1 <- data.frame(typeHousing, satisfaction, contact, counts)
data1$satisfaction <- relevel(data1$satisfaction, ref = 'low')
data1$contact <- relevel(data1$contact, ref = 'low')
housing.glm3 <- polr(satisfaction ~ typeHousing + contact, weights =  counts, data = data1)
df.residual(housing.glm3)
